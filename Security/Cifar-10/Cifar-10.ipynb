{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e4119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "=== Phase 1: Training Clean Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/391 [00:00<?, ?it/s]C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████| 391/391 [02:16<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 01/25 — Loss: 1.6660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:06<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 02/25 — Loss: 1.1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:13<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 03/25 — Loss: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:08<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 04/25 — Loss: 0.8490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:15<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 05/25 — Loss: 0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 06/25 — Loss: 0.6498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:32<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 07/25 — Loss: 0.5703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 08/25 — Loss: 0.5257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 09/25 — Loss: 0.4819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:32<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 10/25 — Loss: 0.4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:33<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 11/25 — Loss: 0.4038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:30<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 12/25 — Loss: 0.3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 13/25 — Loss: 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 14/25 — Loss: 0.3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 15/25 — Loss: 0.2965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 16/25 — Loss: 0.2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 17/25 — Loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:26<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 18/25 — Loss: 0.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:32<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 19/25 — Loss: 0.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:32<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 20/25 — Loss: 0.2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:24<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 21/25 — Loss: 0.1942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:07<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 22/25 — Loss: 0.1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:06<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 23/25 — Loss: 0.1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:07<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 24/25 — Loss: 0.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [02:07<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Clean] Epoch 25/25 — Loss: 0.1499\n",
      "\n",
      "Evaluating clean model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Phase 2: Training Defense Model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/391 [00:00<?, ?it/s]C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Training: 100%|██████████| 391/391 [09:52<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 01/25 — Loss: 1.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:48<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 02/25 — Loss: 1.7299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:40<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 03/25 — Loss: 1.5906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 04/25 — Loss: 1.4842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 05/25 — Loss: 1.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 06/25 — Loss: 1.3321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:38<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 07/25 — Loss: 1.2630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:39<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 08/25 — Loss: 1.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:25<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 09/25 — Loss: 1.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:22<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 10/25 — Loss: 1.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:25<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 11/25 — Loss: 1.0512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:22<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 12/25 — Loss: 1.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:21<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 13/25 — Loss: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:21<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 14/25 — Loss: 0.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:22<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 15/25 — Loss: 0.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:22<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 16/25 — Loss: 0.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:22<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 17/25 — Loss: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:21<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 18/25 — Loss: 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:23<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 19/25 — Loss: 0.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:25<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 20/25 — Loss: 0.7663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:25<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 21/25 — Loss: 0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:22<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 22/25 — Loss: 0.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:23<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 23/25 — Loss: 0.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [09:23<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 24/25 — Loss: 0.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 391/391 [10:37<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Defense] Epoch 25/25 — Loss: 0.6341\n",
      "\n",
      "Evaluating defense model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:117: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_16872\\1199398900.py:132: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== All done! Results saved to results.json ===\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import (\n",
    "    Compose, ToTensor, Normalize,\n",
    "    RandomHorizontalFlip, RandomCrop\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score,\n",
    "    recall_score, f1_score\n",
    ")\n",
    "\n",
    "# ================== Device & AMP Setup ==================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "scaler = GradScaler()\n",
    "\n",
    "# ================== Model Architecture ==================\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, 3, stride, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, 3, 1, 1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth=28, widen_factor=10, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 16\n",
    "        n = (depth - 4) // 6\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.layer1 = self._make_layer(n, 16 * widen_factor, stride=1)\n",
    "        self.layer2 = self._make_layer(n, 32 * widen_factor, stride=2)\n",
    "        self.layer3 = self._make_layer(n, 64 * widen_factor, stride=2)\n",
    "\n",
    "        self.linear = nn.Linear(64 * widen_factor, num_classes)\n",
    "\n",
    "    def _make_layer(self, num_blocks, planes, stride):\n",
    "        layers = [ResidualBlock(self.in_planes, planes, stride)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(ResidualBlock(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = F.avg_pool2d(x, 8)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.linear(x)\n",
    "\n",
    "# ================== Data Loading ==================\n",
    "def get_loaders(batch_size=128, num_workers=8, prefetch_factor=2):\n",
    "    transform_train = Compose([\n",
    "        RandomCrop(32, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "        Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))\n",
    "    ])\n",
    "    transform_test = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010))\n",
    "    ])\n",
    "\n",
    "    train_set = CIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train\n",
    "    )\n",
    "    test_set = CIFAR10(\n",
    "        root='./data', train=False, download=True,\n",
    "        transform=transform_test\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=batch_size,\n",
    "        shuffle=True, num_workers=num_workers,\n",
    "        pin_memory=True, prefetch_factor=prefetch_factor\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=256,\n",
    "        shuffle=False, num_workers=num_workers,\n",
    "        pin_memory=True, prefetch_factor=prefetch_factor\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# ================== Attack Implementations ==================\n",
    "def fgsm_attack(model, images, labels, epsilon):\n",
    "    images.requires_grad_()\n",
    "    with autocast():\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "    scaler.scale(loss).backward()\n",
    "    adv = images + epsilon * images.grad.sign()\n",
    "    return torch.clamp(adv, 0, 1).detach()\n",
    "\n",
    "def pgd_attack(model, images, labels, epsilon, alpha, steps):\n",
    "    orig = images.detach()\n",
    "    # random start\n",
    "    images = orig + torch.empty_like(orig).uniform_(-epsilon, epsilon)\n",
    "    images = torch.clamp(images, 0, 1).detach()\n",
    "\n",
    "    for _ in range(steps):\n",
    "        images.requires_grad_()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "        grad = torch.autograd.grad(loss, images)[0]\n",
    "        images = images + alpha * grad.sign()\n",
    "        images = torch.max(torch.min(images, orig + epsilon), orig - epsilon)\n",
    "        images = torch.clamp(images, 0, 1).detach()\n",
    "    return images\n",
    "\n",
    "# ================== Training & Evaluation ==================\n",
    "def train_model(model, loader, optimizer, scheduler, scaler,\n",
    "                use_defense=False, epsilon=8/255, alpha=2/255, steps=7):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            if use_defense:\n",
    "                adv_images = pgd_attack(\n",
    "                    model, images, labels,\n",
    "                    epsilon=epsilon, alpha=alpha, steps=steps\n",
    "                )\n",
    "                outputs = model(adv_images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "\n",
    "    # clean\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            outputs = model(imgs)\n",
    "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(lbls.cpu().numpy())\n",
    "    results['clean'] = {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, average='macro'),\n",
    "        'recall': recall_score(all_labels, all_preds, average='macro'),\n",
    "        'f1': f1_score(all_labels, all_preds, average='macro'),\n",
    "    }\n",
    "\n",
    "    # adversarial\n",
    "    attacks = {\n",
    "        'fgsm_4':   (fgsm_attack, {'epsilon': 4/255}),\n",
    "        'fgsm_8':   (fgsm_attack, {'epsilon': 8/255}),\n",
    "        'pgd_4_5':  (pgd_attack, {'epsilon':4/255,'alpha':1/255,'steps':5}),\n",
    "        'pgd_8_10': (pgd_attack, {'epsilon':8/255,'alpha':2/255,'steps':10}),\n",
    "    }\n",
    "    for name, (fn, params) in attacks.items():\n",
    "        preds, labels = [], []\n",
    "        for imgs, lbls in loader:\n",
    "            imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "            adv = fn(model, imgs, lbls, **params)\n",
    "            with torch.no_grad():\n",
    "                out = model(adv)\n",
    "            preds.extend(out.argmax(1).cpu().numpy())\n",
    "            labels.extend(lbls.cpu().numpy())\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy_score(labels, preds),\n",
    "            'precision': precision_score(labels, preds, average='macro'),\n",
    "            'recall': recall_score(labels, preds, average='macro'),\n",
    "            'f1': f1_score(labels, preds, average='macro'),\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# ================== Main Script ==================\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader, test_loader = get_loaders(batch_size=128)\n",
    "    results = {}\n",
    "    NUM_EPOCHS = 25\n",
    "\n",
    "    try:\n",
    "        # Phase 1: Clean\n",
    "        print(\"\\n=== Phase 1: Training Clean Model ===\")\n",
    "        model = WideResNet().to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=NUM_EPOCHS, T_mult=1)\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            loss = train_model(\n",
    "                model, train_loader,\n",
    "                optimizer, scheduler,\n",
    "                scaler, use_defense=False\n",
    "            )\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"[Clean] Epoch {epoch+1:02d}/{NUM_EPOCHS} — Loss: {loss:.4f}\")\n",
    "\n",
    "        print(\"\\nEvaluating clean model…\")\n",
    "        results['clean_model'] = evaluate(model, test_loader)\n",
    "        torch.save(model.state_dict(), 'clean_model.pth')\n",
    "        del model, optimizer, scheduler\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Phase 2: Defense\n",
    "        print(\"\\n=== Phase 2: Training Defense Model ===\")\n",
    "        model = WideResNet().to(device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=NUM_EPOCHS, T_mult=1)\n",
    "\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            loss = train_model(\n",
    "                model, train_loader,\n",
    "                optimizer, scheduler,\n",
    "                scaler, use_defense=True,\n",
    "                epsilon=8/255, alpha=2/255, steps=7\n",
    "            )\n",
    "            torch.cuda.empty_cache()\n",
    "            print(f\"[Defense] Epoch {epoch+1:02d}/{NUM_EPOCHS} — Loss: {loss:.4f}\")\n",
    "\n",
    "        print(\"\\nEvaluating defense model…\")\n",
    "        results['defense_model'] = evaluate(model, test_loader)\n",
    "        torch.save(model.state_dict(), 'defense_model.pth')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {e}\\nSaving partial results…\")\n",
    "        with open('results_run2.json', 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        exit(1)\n",
    "\n",
    "    # Saving final results\n",
    "    with open('results_run2.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(\"\\n=== All done! Results saved to results.json ===\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
